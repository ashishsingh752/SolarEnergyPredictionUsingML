{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b2364-f75b-41a5-bd0e-8d40c88c3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate time series into patterns\n",
    "def get_Patterns(TSeries, n_inputs,h):\n",
    "    X,y,z = pd.DataFrame(np.zeros((len(TSeries)-n_inputs-h+1,n_inputs))), pd.DataFrame(), pd.DataFrame()\n",
    "    for i in range(len(TSeries)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_inputs + h - 1\n",
    "        # check if we are beyond the time series\n",
    "        if end_ix > len(TSeries)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        for j in range(n_inputs):\n",
    "            X.loc[i,j]=TSeries.iloc[i+j,0]\n",
    "        i=i+n_inputs\n",
    "        #y=y.append(TSeries.iloc[end_ix], ignore_index = True)\n",
    "        y=pd.concat([y, TSeries.iloc[end_ix]], ignore_index=True)\n",
    "    return pd.DataFrame(X),pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalData should be a Column Vectored DataFrame\n",
    "def minmaxNorm(originalData, lenTrainValidation):\n",
    "    # Maximum Value\n",
    "    max2norm=max(originalData.iloc[0:lenTrainValidation,0])\n",
    "    # Minimum Value\n",
    "    min2norm=min(originalData.iloc[0:lenTrainValidation,0])\n",
    "    lenOriginal=len(originalData)\n",
    "    normalizedData=np.zeros(lenOriginal)   \n",
    "    normalizedData = []\n",
    "    #Normalize using Min-Max Normalization\n",
    "    for i in range (lenOriginal):\n",
    "        normalizedData.append((originalData.iloc[i]-min2norm)/(max2norm-min2norm))    \n",
    "    return pd.DataFrame(normalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c481549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalData and forecastedData should be Column Vectored DataFrames\n",
    "def minmaxDeNorm( originalData, forecastedData, lenTrainValidation):\n",
    "    # Maximum Value\n",
    "    max2norm=max(originalData.iloc[0:lenTrainValidation,0])\n",
    "    # Minimum Value\n",
    "    min2norm=min(originalData.iloc[0:lenTrainValidation,0])\n",
    "    lenOriginal=len(originalData)\n",
    "    denormalizedData=[]   \n",
    "    #De-Normalize using Min-Max Normalization\n",
    "    for i in range (lenOriginal):\n",
    "        denormalizedData.append((forecastedData.iloc[i]*(max2norm-min2norm))+min2norm)  \n",
    "    return pd.DataFrame(denormalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5142a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findRMSE( Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    # RMSE on Train & Validation Set\n",
    "    trainRMSE=0;\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainRMSE=trainRMSE+np.power((forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]),2) \n",
    "    trainRMSE=np.sqrt(trainRMSE/lenTrainValidation)\n",
    "    # RMSE on Test Set\n",
    "    testRMSE=0;\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testRMSE=testRMSE+np.power((forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]),2)\n",
    "    testRMSE=np.sqrt(testRMSE/lenTest)\n",
    "    return trainRMSE, testRMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findMAE(Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    # MAE on Train & Validation Set\n",
    "    trainMAE=0;\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainMAE=trainMAE+np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]) \n",
    "    trainMAE=(trainMAE/(lenTrainValidation));\n",
    "    # MAE on Test Set\n",
    "    testMAE=0;\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testMAE=testMAE+np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0])\n",
    "    testMAE=(testMAE/lenTest);\n",
    "    return trainMAE, testMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Fitness(x,y,lenValid,lenTest,model):\n",
    "    NOP=y.shape[0]\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    xTrain=x.iloc[0:lenTrain,:]\n",
    "    xValid=x.iloc[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x.iloc[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y.iloc[0:lenTrain,0]\n",
    "    yValid=y.iloc[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y.iloc[(lenTrain+lenValid):NOP,0]\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yhatNorm=model.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    return pd.DataFrame(yhatNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82a6b1-5e69-46be-8a30-1a121e38a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the Lynx Time Series into Colab\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Time Series Dataset\n",
    "Timeseries_Data=pd.read_csv('Lynx.csv',header=None)\n",
    "Timeseries_Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c827bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Autocorrelation Plot\") \n",
    "# Providing x-axis name.\n",
    "plt.xlabel(\"Lags\") \n",
    "# Plotting the Autocorrelation plot.\n",
    "plt.acorr(np.array(Timeseries_Data.iloc[:,0], dtype=float), maxlags = 20) \n",
    "# Displaying the plot.\n",
    "print(\"The Autocorrelation plot for the data is:\")\n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199104f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Rug plot â€” sns.rugplot()\n",
    "sns.rugplot(data=Timeseries_Data, height=.03, color='darkblue')\n",
    "sns.histplot(data=Timeseries_Data, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LagLength=10\n",
    "h=1\n",
    "lt=Timeseries_Data.shape[0]\n",
    "lenTrain=int(round(lt*0.7))\n",
    "lenValidation=int(round(lt*0.15))\n",
    "lenTest=int(lt-lenTrain-lenValidation)\n",
    "# NORMALIZE THE DATA\n",
    "normalizedData=minmaxNorm(Timeseries_Data,lenTrain+lenValidation);\n",
    "# Transform the Time Series into Patterns Using Sliding Window\n",
    "X, y = get_Patterns(normalizedData, LagLength, h)\n",
    "model=LinearRegression()\n",
    "name='LinearRegression'\n",
    "file1='./'+str(name)+\"_Accuracy.xlsx\"\n",
    "file2='./'+str(name)+\"_Forecasts.xlsx\"\n",
    "Forecasts=pd.DataFrame()\n",
    "Accuracy=pd.DataFrame()\n",
    "ynorm1=Find_Fitness(X,y,lenValidation,lenTest,model)\n",
    "ynorm=pd.DataFrame(normalizedData.iloc[0:(LagLength+h-1),0])\n",
    "ynorm=pd.concat([ynorm, ynorm1], ignore_index=True)\n",
    "yhat=minmaxDeNorm(Timeseries_Data, ynorm, lenTrain+lenValidation)\n",
    "Accuracy.loc[0,0],Accuracy.loc[0,1]=findRMSE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "Accuracy.loc[0,2],Accuracy.loc[0,3]=findMAE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "Forecasts=pd.concat([Forecasts, yhat.T], ignore_index=True)\n",
    "Accuracy.to_excel(file1,sheet_name='Accuracy',index=False)\n",
    "Forecasts.to_excel(file2,sheet_name='Forecasts',index=False)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec134f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
